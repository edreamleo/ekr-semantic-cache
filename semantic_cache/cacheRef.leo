<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: https://leo-editor.github.io/leo-editor/leo_toc.html -->
<leo_file xmlns:leo="https://leo-editor.github.io/leo-editor/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20250426044347.1"><vh>Startup</vh>
<v t="ekr.20250426044445.1"><vh>@button backup</vh></v>
<v t="ekr.20250427065404.1"><vh>@button check</vh></v>
<v t="ekr.20250512060544.1"><vh>@button run</vh></v>
<v t="ekr.20250512061621.1"><vh>@button test</vh></v>
<v t="ekr.20250514145634.1"><vh>@settings</vh>
<v t="ekr.20250514145537.1"><vh>@data history-list</vh></v>
<v t="ekr.20250515081830.1"><vh>@bool run-flake8-on-write = True</vh></v>
<v t="ekr.20250515081904.1"><vh>@bool run-python-pyflakes-on-write = True</vh></v>
<v t="ekr.20250515082911.1"><vh>@bool beautify-python-code-on-write = True</vh></v>
</v>
<v t="ekr.20250426044713.1"><vh> Recursive import script</vh></v>
</v>
<v t="ekr.20250426202645.1"><vh>--- unused</vh>
<v t="ekr.20250427052613.1"><vh>--- unused imports</vh></v>
<v t="ekr.20250515075715.1"><vh>code to dump tree</vh></v>
</v>
<v t="ekr.20250426050131.1"><vh>--- files</vh>
<v t="ekr.20250512055230.1"><vh>@clean ../setup.cfg </vh></v>
<v t="ekr.20250426050140.1"><vh>@file src/controller.py</vh></v>
<v t="ekr.20250512061658.1"><vh>@file tests/test.py</vh></v>
</v>
<v t="ekr.20250501074906.1"><vh>--- classes</vh>
<v t="ekr.20250512073231.1"><vh>class CacheTests</vh>
<v t="ekr.20250512062255.1"><vh>CT.test_import</vh></v>
<v t="ekr.20250514060210.1"><vh>CT.test_times</vh></v>
</v>
<v t="ekr.20250430053636.61"><vh>class Checker</vh>
<v t="ekr.20250430053636.96"><vh>Checker.__init__</vh></v>
<v t="ekr.20250430053636.97"><vh>Checker.deferFunction</vh></v>
<v t="ekr.20250430053636.98"><vh>Checker._run_deferred</vh></v>
<v t="ekr.20250430053636.99"><vh>Checker._in_doctest</vh></v>
<v t="ekr.20250430053636.100"><vh>Checker.futuresAllowed</vh></v>
<v t="ekr.20250430053636.101"><vh>Checker.futuresAllowed</vh></v>
<v t="ekr.20250430053636.102"><vh>Checker.annotationsFutureEnabled</vh></v>
<v t="ekr.20250430053636.103"><vh>Checker.annotationsFutureEnabled</vh></v>
<v t="ekr.20250430053636.104"><vh>Checker.scope</vh></v>
<v t="ekr.20250430053636.105"><vh>Checker.in_scope</vh></v>
<v t="ekr.20250430053636.106"><vh>Checker.checkDeadScopes</vh></v>
<v t="ekr.20250430053636.107"><vh>Checker.report</vh></v>
<v t="ekr.20250430053636.108"><vh>Checker.getParent</vh></v>
<v t="ekr.20250430053636.109"><vh>Checker.getCommonAncestor</vh></v>
<v t="ekr.20250430053636.110"><vh>Checker.descendantOf</vh></v>
<v t="ekr.20250430053636.111"><vh>Checker._getAncestor</vh></v>
<v t="ekr.20250430053636.112"><vh>Checker.getScopeNode</vh></v>
<v t="ekr.20250430053636.113"><vh>Checker.differentForks</vh></v>
<v t="ekr.20250430053636.114"><vh>Checker.addBinding</vh></v>
<v t="ekr.20250430053636.115"><vh>Checker._unknown_handler</vh></v>
<v t="ekr.20250430053636.116"><vh>Checker.getNodeHandler</vh></v>
<v t="ekr.20250430053636.117"><vh>Checker.handleNodeLoad</vh></v>
<v t="ekr.20250430053636.118"><vh>Checker.handleNodeStore</vh></v>
<v t="ekr.20250430053636.119"><vh>Checker.handleNodeDelete</vh></v>
<v t="ekr.20250430053636.120"><vh>Checker._enter_annotation</vh></v>
<v t="ekr.20250430053636.121"><vh>Checker._in_postponed_annotation</vh></v>
<v t="ekr.20250430053636.122"><vh>Checker.handleChildren</vh></v>
<v t="ekr.20250430053636.123"><vh>Checker.isLiteralTupleUnpacking</vh></v>
<v t="ekr.20250430053636.124"><vh>Checker.isDocstring</vh></v>
<v t="ekr.20250430053636.125"><vh>Checker.getDocstring</vh></v>
<v t="ekr.20250430053636.126"><vh>Checker.handleNode</vh></v>
<v t="ekr.20250430053636.127"><vh>Checker.handleDoctests</vh></v>
<v t="ekr.20250430053636.128"><vh>Checker.handleStringAnnotation</vh></v>
<v t="ekr.20250430053636.129"><vh>Checker.handle_annotation_always_deferred</vh></v>
<v t="ekr.20250430053636.130"><vh>Checker.handleAnnotation</vh></v>
<v t="ekr.20250430053636.131"><vh>Checker.ignore</vh></v>
<v t="ekr.20250430053636.132"><vh>Checker.SUBSCRIPT</vh></v>
<v t="ekr.20250430053636.133"><vh>Checker._handle_string_dot_format</vh></v>
<v t="ekr.20250430053636.134"><vh>Checker.CALL</vh></v>
<v t="ekr.20250430053636.135"><vh>Checker._handle_percent_format</vh></v>
<v t="ekr.20250430053636.136"><vh>Checker.BINOP</vh></v>
<v t="ekr.20250430053636.137"><vh>Checker.CONSTANT</vh></v>
<v t="ekr.20250430053636.138"><vh>Checker.RAISE</vh></v>
<v t="ekr.20250430053636.139"><vh>Checker.JOINEDSTR</vh></v>
<v t="ekr.20250430053636.140"><vh>Checker.DICT</vh></v>
<v t="ekr.20250430053636.141"><vh>Checker.IF</vh></v>
<v t="ekr.20250430053636.142"><vh>Checker.ASSERT</vh></v>
<v t="ekr.20250430053636.143"><vh>Checker.GLOBAL</vh></v>
<v t="ekr.20250430053636.144"><vh>Checker.GENERATOREXP</vh></v>
<v t="ekr.20250430053636.145"><vh>Checker.NAME</vh></v>
<v t="ekr.20250430053636.146"><vh>Checker.CONTINUE</vh></v>
<v t="ekr.20250430053636.147"><vh>Checker.RETURN</vh></v>
<v t="ekr.20250430053636.148"><vh>Checker.YIELD</vh></v>
<v t="ekr.20250430053636.149"><vh>Checker.FUNCTIONDEF</vh></v>
<v t="ekr.20250430053636.150"><vh>Checker.LAMBDA</vh></v>
<v t="ekr.20250430053636.151"><vh>Checker.ARGUMENTS</vh></v>
<v t="ekr.20250430053636.152"><vh>Checker.ARG</vh></v>
<v t="ekr.20250430053636.153"><vh>Checker.CLASSDEF</vh></v>
<v t="ekr.20250430053636.154"><vh>Checker.AUGASSIGN</vh></v>
<v t="ekr.20250430053636.155"><vh>Checker.TUPLE</vh></v>
<v t="ekr.20250430053636.156"><vh>Checker.IMPORT</vh></v>
<v t="ekr.20250430053636.157"><vh>Checker.IMPORTFROM</vh></v>
<v t="ekr.20250430053636.158"><vh>Checker.TRY</vh></v>
<v t="ekr.20250430053636.159"><vh>Checker.EXCEPTHANDLER</vh></v>
<v t="ekr.20250430053636.160"><vh>Checker.ANNASSIGN</vh></v>
<v t="ekr.20250430053636.161"><vh>Checker.COMPARE</vh></v>
<v t="ekr.20250430053636.162"><vh>Checker._match_target</vh></v>
<v t="ekr.20250430053636.163"><vh>Checker._type_param_scope</vh></v>
<v t="ekr.20250430053636.164"><vh>Checker.TYPEVAR</vh></v>
<v t="ekr.20250430053636.165"><vh>Checker.TYPEALIAS</vh></v>
</v>
<v t="ekr.20250427052951.1"><vh>class SemanticCache(SqlitePickleShare)</vh>
<v t="ekr.20250427053445.1"><vh>SemanticCache.__init__</vh></v>
</v>
</v>
<v t="ekr.20250515061233.1"><vh>--- recent</vh>
<v t="ekr.20250427190307.1"><vh>CC.get_changed_files</vh></v>
<v t="ekr.20250514060210.1"></v>
<v t="ekr.20250427190307.1"></v>
<v t="ekr.20250514055617.1"><vh>CC.main (entry)</vh></v>
<v t="ekr.20250428071526.1"><vh>CC.print_stats</vh></v>
</v>
<v t="ekr.20250426191746.1"><vh>*** To do</vh></v>
<v t="ekr.20250512073231.1"></v>
<v t="ekr.20250427190248.1"><vh>class CacheController</vh>
<v t="ekr.20250428033750.1"><vh>CC.__init__</vh></v>
<v t="ekr.20250427200712.1"><vh>CC.commit &amp; close</vh></v>
<v t="ekr.20250428100117.1"><vh>CC.do_semanctics (To do)</vh></v>
<v t="ekr.20250428034510.1"><vh>CC.dump_cache</vh></v>
<v t="ekr.20250427190307.1"></v>
<v t="ekr.20250514055617.1"></v>
<v t="ekr.20250428071526.1"></v>
<v t="ekr.20250427194628.1"><vh>CC.write_cache (revise??)</vh></v>
</v>
<v t="ekr.20250514055617.1"></v>
</vnodes>
<tnodes>
<t tx="ekr.20250426044347.1"></t>
<t tx="ekr.20250426044445.1">"""
Back up this .leo file.

os.environ['LEO_BACKUP'] must be the path to an existing (writable) directory.
"""
c.backup_helper(sub_dir='ekr-cache')
</t>
<t tx="ekr.20250426044713.1">@language python
"""Recursively import all python files in a directory and clean the result."""
@tabwidth -4 # For a better match.
g.cls()

dir_ = r'C:\Python\Python3.13\Lib\site-packages\pyflakes'

c.recursiveImport(
    dir_= dir_,
    kind = '@file', # '@auto', '@clean', '@nosent','@file',
    recursive = True,
    safe_at_file = True,
    theTypes = ['.py',],
    verbose = True,
)
if 1:
    last = c.lastTopLevel()
    last.expand()
    if last.hasChildren():
        last.firstChild().expand()
    c.redraw(last)
print('Done')</t>
<t tx="ekr.20250426050131.1"></t>
<t tx="ekr.20250426191746.1">@language rest

Investigate diffing Ast's.
- Create an artificial diff.
- Give/Take arrays for every namespace.

Later:
- Function: module_path: converts import to path.

@language python
</t>
<t tx="ekr.20250426202645.1"></t>
<t tx="ekr.20250427052613.1"># from leo.core import (
    # leoAPI, leoApp, leoAtFile,  # leoAst,
    # leoBackground,  # leoBridge, # leoBeautify,
    # leoCache, leoChapters, leoColor, leoColorizer,
    # leoCommands, leoConfig,  # leoCompare, leoDebugger,
    # leoExternalFiles,
    # leoFileCommands, leoFind, leoFrame,
    # leoGlobals, leoGui,
    # leoHistory, leoImport,  # leoJupytext,
    # leoKeys, leoMarkup, leoMenu,
    # leoNodes,
    # leoPlugins,  # leoPersistence, leoPrinting, leoPymacs,
    # leoQt,
    # leoRst,  # leoRope,
    # leoSessions, leoShadow,
    # # leoTest2, leoTips, leoTokens,
    # leoUndo, leoVersion,  # leoVim
# )
</t>
<t tx="ekr.20250427052951.1">class SemanticCache(SqlitePickleShare):
    """The persistent cache object"""
    @others

    def _makedirs(self, fn: str, mode: int = 0o777) -&gt; None:
        raise NotImplementedError

    def _walkfiles(self, s: str, pattern: Any = None) -&gt; None:
        raise NotImplementedError
</t>
<t tx="ekr.20250427053445.1">def __init__(self, root: str) -&gt; None:  # pylint: disable=super-init-not-called
    """ctor for the SemanticCache object."""
    self.root = root  # For traces.
    dbfile = ':memory:' if g.unitTesting else root
    self.conn = sqlite3.connect(dbfile)
    self.init_dbtables(self.conn)

    def loadz(data: Value) -&gt; Optional[Value]:
        if data:
            # Retain this code for maximum compatibility.
            try:
                val = pickle.loads(zlib.decompress(data))
            except(ValueError, TypeError):
                g.es("Unpickling error - Python 3 data accessed from Python 2?")
                return None
            return val
        return None

    def dumpz(val: Value) -&gt; Value:
        try:
            # Use Python 2's highest protocol, 2, if possible
            data = pickle.dumps(val, protocol=2)
        except Exception:
            # Use best available if that doesn't work (unlikely)
            data = pickle.dumps(val, pickle.HIGHEST_PROTOCOL)
        return sqlite3.Binary(zlib.compress(data))

    self.loader = loadz
    self.dumper = dumpz
    self.reset_protocol_in_values()
</t>
<t tx="ekr.20250427065404.1">"""Check source files with mypy and pylint."""
import os
import sys

g.cls()
os.chdir(r'C:\Repos\ekr-semantic-cache\semantic_cache\src')
path = 'controller.py'
rc_file = r'C:\Users\Dev\.leo\.pylintrc'
g.execute_shell_commands([
    f"python -m mypy {path}",
    f"python -m pylint --rcfile {rc_file} {path}",
])
print('Done')</t>
<t tx="ekr.20250427190248.1">class CacheController:
    """The driver class for the semantic caching project."""

    @others
</t>
<t tx="ekr.20250427190307.1">def get_changed_files(self) -&gt; list[str]:
    """
    Update the tree and modification file for all new and changed files.
    """
    trace = not g.unitTesting
    t1 = time.perf_counter()
    updated_paths: list[str] = []
    for path in self.paths:
        mod_time = os.path.getmtime(path)
        old_mod_time = self.mod_time_dict.get(path, None)
        if old_mod_time is not None and mod_time &gt; old_mod_time:
            if trace:
                kind = 'Create' if old_mod_time is None else 'Update'
                print(f"{kind} {path} {time.ctime(mod_time)}")
            updated_paths.append(path)
            contents = g.readFile(path)
            tree = parse_ast(contents)
            self.module_dict[path] = tree
            self.mod_time_dict[path] = mod_time
    t2 = time.perf_counter()
    self.stats.append(('Find changed', t2 - t1))
    if trace and updated_paths:
        g.printObj(updated_paths, tag='Updated files')
    return updated_paths
</t>
<t tx="ekr.20250427194628.1">def write_cache(self):
    """Update the persistent cache with all data."""

    # All keys are full path names.
    t1 = time.perf_counter()
    self.cache['module_dict'] = self.module_dict
    self.cache['mod_time_dict'] = self.mod_time_dict
    t2 = time.perf_counter()
    self.stats.append(('Write cache', (t2 - t1)))
</t>
<t tx="ekr.20250427200712.1">def commit(self) -&gt; None:
    """Commit the cache."""
    t1 = time.perf_counter()
    self.cache.conn.commit()
    t2 = time.perf_counter()
    self.stats.append(('Commit cache', t2 - t1))

def close(self) -&gt; None:
    """Close the cache."""
    t1 = time.perf_counter()
    self.cache.conn.close()
    t2 = time.perf_counter()
    self.stats.append(('Close cache', t2 - t1))
</t>
<t tx="ekr.20250428033750.1">def __init__(self) -&gt; None:

    # Set the global start time.
    self.start_time = t1 = time.perf_counter()

    # Load the persistent cache.
    self.cache = SemanticCache('semantic_cache.db')

    # The list of all paths to be considered.
    self.paths: list[str] = [
        f"{core_path}{os.sep}{z}.py"
        for z in core_names if os.path.exists(z)
    ]

    # Dictionaries. Keys are full path names.
    self.module_dict: dict[str, Optional[Node]] = self.cache.get('module_dict') or {}
    self.mod_time_dict: dict[str, float] = self.cache.get('mod_time_dict') or {}

    # Stats:
    t2 = time.perf_counter()
    self.stats: list[tuple[str, float]] = [
        ('Load cache', (t2 - t1)),
    ]

</t>
<t tx="ekr.20250428034510.1">def dump_cache(self):
    """Dump the contents of the data to be written to the cache."""

    # Dump the modification times
    print('Dump of mod_time_dict...')
    for key, val in self.mod_time_dict.items():
        print(f"{val:&lt;18} {key}")
</t>
<t tx="ekr.20250428071526.1">def print_stats(self, updated_files: list[str]) -&gt; None:

    # Get the max length of all keys.
    pad_n = 5  # A reasonable default.
    for key, value in self.stats:
        pad_n = max(pad_n, len(key))

    def pad(key: str) -&gt; str:
        pad_s = max(0, pad_n - len(key))
        return pad_s * ' ' + key

    # Print the stats.
    n = len(updated_files)
    print('')
    print(f"{n} updated file{g.plural(n)}")
    for key, value in self.stats:
        print(f"{pad(key)} {value:.2f} sec.")
</t>
<t tx="ekr.20250428100117.1">def do_semantics(self, updated_files: list[str]) -&gt; None:
    """
    Do all semantics on updated files:
    - Recompute diffs,
    - Recompute gives/takes (defs/refs) data.
    """
    pass
</t>
<t tx="ekr.20250430053636.100">@property
def futuresAllowed(self):
    if not all(isinstance(scope, ModuleScope)
               for scope in self.scopeStack):
        return False

    return self.scope._futures_allowed
</t>
<t tx="ekr.20250430053636.101">@futuresAllowed.setter
def futuresAllowed(self, value):
    assert value is False
    if isinstance(self.scope, ModuleScope):
        self.scope._futures_allowed = False
</t>
<t tx="ekr.20250430053636.102">@property
def annotationsFutureEnabled(self):
    scope = self.scopeStack[0]
    if not isinstance(scope, ModuleScope):
        return False
    return scope._annotations_future_enabled
</t>
<t tx="ekr.20250430053636.103">@annotationsFutureEnabled.setter
def annotationsFutureEnabled(self, value):
    assert value is True
    assert isinstance(self.scope, ModuleScope)
    self.scope._annotations_future_enabled = True
</t>
<t tx="ekr.20250430053636.104">@property
def scope(self):
    return self.scopeStack[-1]
</t>
<t tx="ekr.20250430053636.105">@contextlib.contextmanager
def in_scope(self, cls):
    self.scopeStack.append(cls())
    try:
        yield
    finally:
        self.deadScopes.append(self.scopeStack.pop())
</t>
<t tx="ekr.20250430053636.106">def checkDeadScopes(self):
    """
    Look at scopes which have been fully examined and report names in them
    which were imported but unused.
    """
    for scope in self.deadScopes:
        # imports in classes are public members
        if isinstance(scope, ClassScope):
            continue

        if isinstance(scope, FunctionScope):
            for name, binding in scope.unused_assignments():
                self.report(messages.UnusedVariable, binding.source, name)
            for name, binding in scope.unused_annotations():
                self.report(messages.UnusedAnnotation, binding.source, name)

        all_binding = scope.get('__all__')
        if all_binding and not isinstance(all_binding, ExportBinding):
            all_binding = None

        if all_binding:
            all_names = set(all_binding.names)
            undefined = [
                name for name in all_binding.names
                if name not in scope
            ]
        else:
            all_names = undefined = []

        if undefined:
            if not scope.importStarred and \
               os.path.basename(self.filename) != '__init__.py':
                # Look for possible mistakes in the export list
                for name in undefined:
                    self.report(messages.UndefinedExport,
                                scope['__all__'].source, name)

            # mark all import '*' as used by the undefined in __all__
            if scope.importStarred:
                from_list = []
                for binding in scope.values():
                    if isinstance(binding, StarImportation):
                        binding.used = all_binding
                        from_list.append(binding.fullName)
                # report * usage, with a list of possible sources
                from_list = ', '.join(sorted(from_list))
                for name in undefined:
                    self.report(messages.ImportStarUsage,
                                scope['__all__'].source, name, from_list)

        # Look for imported names that aren't used.
        for value in scope.values():
            if isinstance(value, Importation):
                used = value.used or value.name in all_names
                if not used:
                    messg = messages.UnusedImport
                    self.report(messg, value.source, str(value))
                for node in value.redefined:
                    if isinstance(self.getParent(node), FOR_TYPES):
                        messg = messages.ImportShadowedByLoopVar
                    elif used:
                        continue
                    else:
                        messg = messages.RedefinedWhileUnused
                    self.report(messg, node, value.name, value.source)
</t>
<t tx="ekr.20250430053636.107">def report(self, messageClass, *args, **kwargs):
    self.messages.append(messageClass(self.filename, *args, **kwargs))
</t>
<t tx="ekr.20250430053636.108">def getParent(self, node):
    # Lookup the first parent which is not Tuple, List or Starred
    while True:
        node = node._pyflakes_parent
        if not hasattr(node, 'elts') and not hasattr(node, 'ctx'):
            return node
</t>
<t tx="ekr.20250430053636.109">def getCommonAncestor(self, lnode, rnode, stop):
    if (
            stop in (lnode, rnode) or
            not (
                hasattr(lnode, '_pyflakes_parent') and
                hasattr(rnode, '_pyflakes_parent')
            )
    ):
        return None
    if lnode is rnode:
        return lnode

    if (lnode._pyflakes_depth &gt; rnode._pyflakes_depth):
        return self.getCommonAncestor(lnode._pyflakes_parent, rnode, stop)
    if (lnode._pyflakes_depth &lt; rnode._pyflakes_depth):
        return self.getCommonAncestor(lnode, rnode._pyflakes_parent, stop)
    return self.getCommonAncestor(
        lnode._pyflakes_parent,
        rnode._pyflakes_parent,
        stop,
    )
</t>
<t tx="ekr.20250430053636.110">def descendantOf(self, node, ancestors, stop):
    for a in ancestors:
        if self.getCommonAncestor(node, a, stop):
            return True
    return False
</t>
<t tx="ekr.20250430053636.111">def _getAncestor(self, node, ancestor_type):
    parent = node
    while True:
        if parent is self.root:
            return None
        parent = self.getParent(parent)
        if isinstance(parent, ancestor_type):
            return parent
</t>
<t tx="ekr.20250430053636.112">def getScopeNode(self, node):
    return self._getAncestor(node, tuple(Checker._ast_node_scope.keys()))
</t>
<t tx="ekr.20250430053636.113">def differentForks(self, lnode, rnode):
    """True, if lnode and rnode are located on different forks of IF/TRY"""
    ancestor = self.getCommonAncestor(lnode, rnode, self.root)
    parts = getAlternatives(ancestor)
    if parts:
        for items in parts:
            if self.descendantOf(lnode, items, ancestor) ^ \
               self.descendantOf(rnode, items, ancestor):
                return True
    return False
</t>
<t tx="ekr.20250430053636.114">def addBinding(self, node, value):
    """
    Called when a binding is altered.

    - `node` is the statement responsible for the change
    - `value` is the new value, a Binding instance
    """
    # assert value.source in (node, node._pyflakes_parent):
    for scope in self.scopeStack[::-1]:
        if value.name in scope:
            break
    existing = scope.get(value.name)

    if (existing and not isinstance(existing, Builtin) and
            not self.differentForks(node, existing.source)):

        parent_stmt = self.getParent(value.source)
        if isinstance(existing, Importation) and isinstance(parent_stmt, FOR_TYPES):
            self.report(messages.ImportShadowedByLoopVar,
                        node, value.name, existing.source)

        elif scope is self.scope:
            if (
                    (not existing.used and value.redefines(existing)) and
                    (value.name != '_' or isinstance(existing, Importation)) and
                    not is_typing_overload(existing, self.scopeStack)
            ):
                self.report(messages.RedefinedWhileUnused,
                            node, value.name, existing.source)

        elif isinstance(existing, Importation) and value.redefines(existing):
            existing.redefined.append(node)

    if value.name in self.scope:
        # then assume the rebound name is used as a global or within a loop
        value.used = self.scope[value.name].used

    # don't treat annotations as assignments if there is an existing value
    # in scope
    if value.name not in self.scope or not isinstance(value, Annotation):
        cur_scope_pos = -1
        # As per PEP 572, use scope in which outermost generator is defined
        while (
            isinstance(value, NamedExprAssignment) and
            isinstance(self.scopeStack[cur_scope_pos], GeneratorScope)
        ):
            cur_scope_pos -= 1
        self.scopeStack[cur_scope_pos][value.name] = value
</t>
<t tx="ekr.20250430053636.115">def _unknown_handler(self, node):
    # this environment variable configures whether to error on unknown
    # ast types.
    #
    # this is silent by default but the error is enabled for the pyflakes
    # testsuite.
    #
    # this allows new syntax to be added to python without *requiring*
    # changes from the pyflakes side.  but will still produce an error
    # in the pyflakes testsuite (so more specific handling can be added if
    # needed).
    if os.environ.get('PYFLAKES_ERROR_UNKNOWN'):
        raise NotImplementedError(f'Unexpected type: {type(node)}')
    else:
        self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.116">def getNodeHandler(self, node_class):
    try:
        return self._nodeHandlers[node_class]
    except KeyError:
        nodeType = node_class.__name__.upper()
    self._nodeHandlers[node_class] = handler = getattr(
        self, nodeType, self._unknown_handler,
    )
    return handler
</t>
<t tx="ekr.20250430053636.117">def handleNodeLoad(self, node, parent):
    name = getNodeName(node)
    if not name:
        return

    # only the following can access class scoped variables (since classes
    # aren't really a scope)
    # - direct accesses (not within a nested scope)
    # - generators
    # - type annotations (for generics, etc.)
    can_access_class_vars = None
    importStarred = None

    # try enclosing function scopes and global scope
    for scope in self.scopeStack[-1::-1]:
        if isinstance(scope, ClassScope):
            if name == '__class__':
                return
            elif can_access_class_vars is False:
                # only generators used in a class scope can access the
                # names of the class. this is skipped during the first
                # iteration
                continue

        binding = scope.get(name, None)
        if isinstance(binding, Annotation) and not self._in_postponed_annotation:
            scope[name].used = (self.scope, node)
            continue

        if name == 'print' and isinstance(binding, Builtin):
            if (isinstance(parent, ast.BinOp) and
                    isinstance(parent.op, ast.RShift)):
                self.report(messages.InvalidPrintSyntax, node)

        try:
            scope[name].used = (self.scope, node)

            # if the name of SubImportation is same as
            # alias of other Importation and the alias
            # is used, SubImportation also should be marked as used.
            n = scope[name]
            if isinstance(n, Importation) and n._has_alias():
                try:
                    scope[n.fullName].used = (self.scope, node)
                except KeyError:
                    pass
        except KeyError:
            pass
        else:
            return

        importStarred = importStarred or scope.importStarred

        if can_access_class_vars is not False:
            can_access_class_vars = isinstance(
                scope, (TypeScope, GeneratorScope),
            )

    if importStarred:
        from_list = []

        for scope in self.scopeStack[-1::-1]:
            for binding in scope.values():
                if isinstance(binding, StarImportation):
                    # mark '*' imports as used for each scope
                    binding.used = (self.scope, node)
                    from_list.append(binding.fullName)

        # report * usage, with a list of possible sources
        from_list = ', '.join(sorted(from_list))
        self.report(messages.ImportStarUsage, node, name, from_list)
        return

    if name == '__path__' and os.path.basename(self.filename) == '__init__.py':
        # the special name __path__ is valid only in packages
        return

    if name in DetectClassScopedMagic.names and isinstance(self.scope, ClassScope):
        return

    # protected with a NameError handler?
    if 'NameError' not in self.exceptHandlers[-1]:
        self.report(messages.UndefinedName, node, name)
</t>
<t tx="ekr.20250430053636.118">def handleNodeStore(self, node):
    name = getNodeName(node)
    if not name:
        return
    # if the name hasn't already been defined in the current scope
    if isinstance(self.scope, FunctionScope) and name not in self.scope:
        # for each function or module scope above us
        for scope in self.scopeStack[:-1]:
            if not isinstance(scope, (FunctionScope, ModuleScope)):
                continue
            # if the name was defined in that scope, and the name has
            # been accessed already in the current scope, and hasn't
            # been declared global
            used = name in scope and scope[name].used
            if used and used[0] is self.scope and name not in self.scope.globals:
                # then it's probably a mistake
                self.report(messages.UndefinedLocal,
                            scope[name].used[1], name, scope[name].source)
                break

    parent_stmt = self.getParent(node)
    if isinstance(parent_stmt, ast.AnnAssign) and parent_stmt.value is None:
        binding = Annotation(name, node)
    elif isinstance(parent_stmt, (FOR_TYPES, ast.comprehension)) or (
            parent_stmt != node._pyflakes_parent and
            not self.isLiteralTupleUnpacking(parent_stmt)):
        binding = Binding(name, node)
    elif (
            name == '__all__' and
            isinstance(self.scope, ModuleScope) and
            isinstance(
                node._pyflakes_parent,
                (ast.Assign, ast.AugAssign, ast.AnnAssign)
            )
    ):
        binding = ExportBinding(name, node._pyflakes_parent, self.scope)
    elif isinstance(parent_stmt, ast.NamedExpr):
        binding = NamedExprAssignment(name, node)
    else:
        binding = Assignment(name, node)
    self.addBinding(node, binding)
</t>
<t tx="ekr.20250430053636.119">def handleNodeDelete(self, node):

    def on_conditional_branch():
        """
        Return `True` if node is part of a conditional body.
        """
        current = getattr(node, '_pyflakes_parent', None)
        while current:
            if isinstance(current, (ast.If, ast.While, ast.IfExp)):
                return True
            current = getattr(current, '_pyflakes_parent', None)
        return False

    name = getNodeName(node)
    if not name:
        return

    if on_conditional_branch():
        # We cannot predict if this conditional branch is going to
        # be executed.
        return

    if isinstance(self.scope, FunctionScope) and name in self.scope.globals:
        self.scope.globals.remove(name)
    else:
        try:
            del self.scope[name]
        except KeyError:
            self.report(messages.UndefinedName, node, name)
</t>
<t tx="ekr.20250430053636.120">@contextlib.contextmanager
def _enter_annotation(self, ann_type=AnnotationState.BARE):
    orig, self._in_annotation = self._in_annotation, ann_type
    try:
        yield
    finally:
        self._in_annotation = orig
</t>
<t tx="ekr.20250430053636.121">@property
def _in_postponed_annotation(self):
    return (
        self._in_annotation == AnnotationState.STRING or
        self.annotationsFutureEnabled
    )
</t>
<t tx="ekr.20250430053636.122">def handleChildren(self, tree, omit=None):
    for node in iter_child_nodes(tree, omit=omit):
        self.handleNode(node, tree)
</t>
<t tx="ekr.20250430053636.123">def isLiteralTupleUnpacking(self, node):
    if isinstance(node, ast.Assign):
        for child in node.targets + [node.value]:
            if not hasattr(child, 'elts'):
                return False
        return True
</t>
<t tx="ekr.20250430053636.124">def isDocstring(self, node):
    """
    Determine if the given node is a docstring, as long as it is at the
    correct place in the node tree.
    """
    return (
        isinstance(node, ast.Expr) and
        isinstance(node.value, ast.Constant) and
        isinstance(node.value.value, str)
    )
</t>
<t tx="ekr.20250430053636.125">def getDocstring(self, node):
    if (
            isinstance(node, ast.Expr) and
            isinstance(node.value, ast.Constant) and
            isinstance(node.value.value, str)
    ):
        return node.value.value, node.lineno - 1
    else:
        return None, None
</t>
<t tx="ekr.20250430053636.126">def handleNode(self, node, parent):
    if node is None:
        return
    if self.offset and getattr(node, 'lineno', None) is not None:
        node.lineno += self.offset[0]
        node.col_offset += self.offset[1]
    if (
            self.futuresAllowed and
            self.nodeDepth == 0 and
            not isinstance(node, ast.ImportFrom) and
            not self.isDocstring(node)
    ):
        self.futuresAllowed = False
    self.nodeDepth += 1
    node._pyflakes_depth = self.nodeDepth
    node._pyflakes_parent = parent
    try:
        handler = self.getNodeHandler(node.__class__)
        handler(node)
    finally:
        self.nodeDepth -= 1
</t>
<t tx="ekr.20250430053636.127">_getDoctestExamples = doctest.DocTestParser().get_examples

def handleDoctests(self, node):
    try:
        (docstring, node_lineno) = self.getDocstring(node.body[0])
        examples = docstring and self._getDoctestExamples(docstring)
    except (ValueError, IndexError):
        # e.g. line 6 of the docstring for &lt;string&gt; has inconsistent
        # leading whitespace: ...
        return
    if not examples:
        return

    # Place doctest in module scope
    saved_stack = self.scopeStack
    self.scopeStack = [self.scopeStack[0]]
    node_offset = self.offset or (0, 0)
    with self.in_scope(DoctestScope):
        if '_' not in self.scopeStack[0]:
            self.addBinding(None, Builtin('_'))
        for example in examples:
            try:
                tree = ast.parse(example.source, "&lt;doctest&gt;")
            except SyntaxError as e:
                position = (node_lineno + example.lineno + e.lineno,
                            example.indent + 4 + (e.offset or 0))
                self.report(messages.DoctestSyntaxError, node, position)
            else:
                self.offset = (node_offset[0] + node_lineno + example.lineno,
                               node_offset[1] + example.indent + 4)
                self.handleChildren(tree)
                self.offset = node_offset
    self.scopeStack = saved_stack
</t>
<t tx="ekr.20250430053636.128">@in_string_annotation
def handleStringAnnotation(self, s, node, ref_lineno, ref_col_offset, err):
    try:
        tree = ast.parse(s)
    except SyntaxError:
        self.report(err, node, s)
        return

    body = tree.body
    if len(body) != 1 or not isinstance(body[0], ast.Expr):
        self.report(err, node, s)
        return

    parsed_annotation = tree.body[0].value
    for descendant in ast.walk(parsed_annotation):
        if (
                'lineno' in descendant._attributes and
                'col_offset' in descendant._attributes
        ):
            descendant.lineno = ref_lineno
            descendant.col_offset = ref_col_offset

    self.handleNode(parsed_annotation, node)
</t>
<t tx="ekr.20250430053636.129">def handle_annotation_always_deferred(self, annotation, parent):
    fn = in_annotation(Checker.handleNode)
    self.deferFunction(lambda: fn(self, annotation, parent))
</t>
<t tx="ekr.20250430053636.130">@in_annotation
def handleAnnotation(self, annotation, node):
    if (
            isinstance(annotation, ast.Constant) and
            isinstance(annotation.value, str)
    ):
        # Defer handling forward annotation.
        self.deferFunction(functools.partial(
            self.handleStringAnnotation,
            annotation.value,
            node,
            annotation.lineno,
            annotation.col_offset,
            messages.ForwardAnnotationSyntaxError,
        ))
    elif self.annotationsFutureEnabled:
        self.handle_annotation_always_deferred(annotation, node)
    else:
        self.handleNode(annotation, node)
</t>
<t tx="ekr.20250430053636.131">def ignore(self, node):
    pass
</t>
<t tx="ekr.20250430053636.132"># "stmt" type nodes
DELETE = FOR = ASYNCFOR = WHILE = WITH = WITHITEM = ASYNCWITH = \
    EXPR = ASSIGN = handleChildren

PASS = ignore

# "expr" type nodes
BOOLOP = UNARYOP = SET = ATTRIBUTE = STARRED = NAMECONSTANT = \
    NAMEDEXPR = handleChildren

def SUBSCRIPT(self, node):
    if _is_name_or_attr(node.value, 'Literal'):
        with self._enter_annotation(AnnotationState.NONE):
            self.handleChildren(node)
    elif _is_name_or_attr(node.value, 'Annotated'):
        self.handleNode(node.value, node)

        # py39+
        if isinstance(node.slice, ast.Tuple):
            slice_tuple = node.slice
        # &lt;py39
        elif (
                isinstance(node.slice, ast.Index) and
                isinstance(node.slice.value, ast.Tuple)
        ):
            slice_tuple = node.slice.value
        else:
            slice_tuple = None

        # not a multi-arg `Annotated`
        if slice_tuple is None or len(slice_tuple.elts) &lt; 2:
            self.handleNode(node.slice, node)
        else:
            # the first argument is the type
            self.handleNode(slice_tuple.elts[0], node)
            # the rest of the arguments are not
            with self._enter_annotation(AnnotationState.NONE):
                for arg in slice_tuple.elts[1:]:
                    self.handleNode(arg, node)

        self.handleNode(node.ctx, node)
    else:
        if _is_any_typing_member(node.value, self.scopeStack):
            with self._enter_annotation():
                self.handleChildren(node)
        else:
            self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.133">def _handle_string_dot_format(self, node):
    try:
        placeholders = tuple(parse_format_string(node.func.value.value))
    except ValueError as e:
        self.report(messages.StringDotFormatInvalidFormat, node, e)
        return

    auto = None
    next_auto = 0

    placeholder_positional = set()
    placeholder_named = set()

    def _add_key(fmtkey):
        """Returns True if there is an error which should early-exit"""
        nonlocal auto, next_auto

        if fmtkey is None:  # end of string or `{` / `}` escapes
            return False

        # attributes / indices are allowed in `.format(...)`
        fmtkey, _, _ = fmtkey.partition('.')
        fmtkey, _, _ = fmtkey.partition('[')

        try:
            fmtkey = int(fmtkey)
        except ValueError:
            pass
        else:  # fmtkey was an integer
            if auto is True:
                self.report(messages.StringDotFormatMixingAutomatic, node)
                return True
            else:
                auto = False

        if fmtkey == '':
            if auto is False:
                self.report(messages.StringDotFormatMixingAutomatic, node)
                return True
            else:
                auto = True

            fmtkey = next_auto
            next_auto += 1

        if isinstance(fmtkey, int):
            placeholder_positional.add(fmtkey)
        else:
            placeholder_named.add(fmtkey)

        return False

    for _, fmtkey, spec, _ in placeholders:
        if _add_key(fmtkey):
            return

        # spec can also contain format specifiers
        if spec is not None:
            try:
                spec_placeholders = tuple(parse_format_string(spec))
            except ValueError as e:
                self.report(messages.StringDotFormatInvalidFormat, node, e)
                return

            for _, spec_fmtkey, spec_spec, _ in spec_placeholders:
                # can't recurse again
                if spec_spec is not None and '{' in spec_spec:
                    self.report(
                        messages.StringDotFormatInvalidFormat,
                        node,
                        'Max string recursion exceeded',
                    )
                    return
                if _add_key(spec_fmtkey):
                    return

    # bail early if there is *args or **kwargs
    if (
            # *args
            any(isinstance(arg, ast.Starred) for arg in node.args) or
            # **kwargs
            any(kwd.arg is None for kwd in node.keywords)
    ):
        return

    substitution_positional = set(range(len(node.args)))
    substitution_named = {kwd.arg for kwd in node.keywords}

    extra_positional = substitution_positional - placeholder_positional
    extra_named = substitution_named - placeholder_named

    missing_arguments = (
        (placeholder_positional | placeholder_named) -
        (substitution_positional | substitution_named)
    )

    if extra_positional:
        self.report(
            messages.StringDotFormatExtraPositionalArguments,
            node,
            ', '.join(sorted(str(x) for x in extra_positional)),
        )
    if extra_named:
        self.report(
            messages.StringDotFormatExtraNamedArguments,
            node,
            ', '.join(sorted(extra_named)),
        )
    if missing_arguments:
        self.report(
            messages.StringDotFormatMissingArgument,
            node,
            ', '.join(sorted(str(x) for x in missing_arguments)),
        )
</t>
<t tx="ekr.20250430053636.134">def CALL(self, node):
    if (
            isinstance(node.func, ast.Attribute) and
            isinstance(node.func.value, ast.Constant) and
            isinstance(node.func.value.value, str) and
            node.func.attr == 'format'
    ):
        self._handle_string_dot_format(node)

    omit = []
    annotated = []
    not_annotated = []

    if (
        _is_typing(node.func, 'cast', self.scopeStack) and
        len(node.args) &gt;= 1
    ):
        with self._enter_annotation():
            self.handleNode(node.args[0], node)

    elif _is_typing(node.func, 'TypeVar', self.scopeStack):

        # TypeVar("T", "int", "str")
        omit += ["args"]
        annotated += [arg for arg in node.args[1:]]

        # TypeVar("T", bound="str")
        omit += ["keywords"]
        annotated += [k.value for k in node.keywords if k.arg == "bound"]
        not_annotated += [
            (k, ["value"] if k.arg == "bound" else None)
            for k in node.keywords
        ]

    elif _is_typing(node.func, "TypedDict", self.scopeStack):
        # TypedDict("a", {"a": int})
        if len(node.args) &gt; 1 and isinstance(node.args[1], ast.Dict):
            omit += ["args"]
            annotated += node.args[1].values
            not_annotated += [
                (arg, ["values"] if i == 1 else None)
                for i, arg in enumerate(node.args)
            ]

        # TypedDict("a", a=int)
        omit += ["keywords"]
        annotated += [k.value for k in node.keywords]
        not_annotated += [(k, ["value"]) for k in node.keywords]

    elif _is_typing(node.func, "NamedTuple", self.scopeStack):
        # NamedTuple("a", [("a", int)])
        if (
            len(node.args) &gt; 1 and
            isinstance(node.args[1], (ast.Tuple, ast.List)) and
            all(isinstance(x, (ast.Tuple, ast.List)) and
                len(x.elts) == 2 for x in node.args[1].elts)
        ):
            omit += ["args"]
            annotated += [elt.elts[1] for elt in node.args[1].elts]
            not_annotated += [(elt.elts[0], None) for elt in node.args[1].elts]
            not_annotated += [
                (arg, ["elts"] if i == 1 else None)
                for i, arg in enumerate(node.args)
            ]
            not_annotated += [(elt, "elts") for elt in node.args[1].elts]

        # NamedTuple("a", a=int)
        omit += ["keywords"]
        annotated += [k.value for k in node.keywords]
        not_annotated += [(k, ["value"]) for k in node.keywords]

    if omit:
        with self._enter_annotation(AnnotationState.NONE):
            for na_node, na_omit in not_annotated:
                self.handleChildren(na_node, omit=na_omit)
            self.handleChildren(node, omit=omit)

        with self._enter_annotation():
            for annotated_node in annotated:
                self.handleNode(annotated_node, node)
    else:
        self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.135">def _handle_percent_format(self, node):
    try:
        placeholders = parse_percent_format(node.left.value)
    except ValueError:
        self.report(
            messages.PercentFormatInvalidFormat,
            node,
            'incomplete format',
        )
        return

    named = set()
    positional_count = 0
    positional = None
    for _, placeholder in placeholders:
        if placeholder is None:
            continue
        name, _, width, precision, conversion = placeholder

        if conversion == '%':
            continue

        if conversion not in VALID_CONVERSIONS:
            self.report(
                messages.PercentFormatUnsupportedFormatCharacter,
                node,
                conversion,
            )

        if positional is None and conversion:
            positional = name is None

        for part in (width, precision):
            if part is not None and '*' in part:
                if not positional:
                    self.report(
                        messages.PercentFormatStarRequiresSequence,
                        node,
                    )
                else:
                    positional_count += 1

        if positional and name is not None:
            self.report(
                messages.PercentFormatMixedPositionalAndNamed,
                node,
            )
            return
        elif not positional and name is None:
            self.report(
                messages.PercentFormatMixedPositionalAndNamed,
                node,
            )
            return

        if positional:
            positional_count += 1
        else:
            named.add(name)

    if (
            isinstance(node.right, (ast.List, ast.Tuple)) and
            # does not have any *splats (py35+ feature)
            not any(
                isinstance(elt, ast.Starred)
                for elt in node.right.elts
            )
    ):
        substitution_count = len(node.right.elts)
        if positional and positional_count != substitution_count:
            self.report(
                messages.PercentFormatPositionalCountMismatch,
                node,
                positional_count,
                substitution_count,
            )
        elif not positional:
            self.report(messages.PercentFormatExpectedMapping, node)

    if (
            isinstance(node.right, ast.Dict) and
            all(
                isinstance(k, ast.Constant) and isinstance(k.value, str)
                for k in node.right.keys
            )
    ):
        if positional and positional_count &gt; 1:
            self.report(messages.PercentFormatExpectedSequence, node)
            return

        substitution_keys = {k.value for k in node.right.keys}
        extra_keys = substitution_keys - named
        missing_keys = named - substitution_keys
        if not positional and extra_keys:
            self.report(
                messages.PercentFormatExtraNamedArguments,
                node,
                ', '.join(sorted(extra_keys)),
            )
        if not positional and missing_keys:
            self.report(
                messages.PercentFormatMissingArgument,
                node,
                ', '.join(sorted(missing_keys)),
            )
</t>
<t tx="ekr.20250430053636.136">def BINOP(self, node):
    if (
            isinstance(node.op, ast.Mod) and
            isinstance(node.left, ast.Constant) and
            isinstance(node.left.value, str)
    ):
        self._handle_percent_format(node)
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.137">def CONSTANT(self, node):
    if isinstance(node.value, str) and self._in_annotation:
        fn = functools.partial(
            self.handleStringAnnotation,
            node.value,
            node,
            node.lineno,
            node.col_offset,
            messages.ForwardAnnotationSyntaxError,
        )
        self.deferFunction(fn)
</t>
<t tx="ekr.20250430053636.138"># "slice" type nodes
SLICE = EXTSLICE = INDEX = handleChildren

# expression contexts are node instances too, though being constants
LOAD = STORE = DEL = AUGLOAD = AUGSTORE = PARAM = ignore

# same for operators
AND = OR = ADD = SUB = MULT = DIV = MOD = POW = LSHIFT = RSHIFT = \
    BITOR = BITXOR = BITAND = FLOORDIV = INVERT = NOT = UADD = USUB = \
    EQ = NOTEQ = LT = LTE = GT = GTE = IS = ISNOT = IN = NOTIN = \
    MATMULT = ignore

def RAISE(self, node):
    self.handleChildren(node)

    arg = node.exc

    if isinstance(arg, ast.Call):
        if is_notimplemented_name_node(arg.func):
            # Handle "raise NotImplemented(...)"
            self.report(messages.RaiseNotImplemented, node)
    elif is_notimplemented_name_node(arg):
        # Handle "raise NotImplemented"
        self.report(messages.RaiseNotImplemented, node)
</t>
<t tx="ekr.20250430053636.139"># additional node types
COMPREHENSION = KEYWORD = FORMATTEDVALUE = handleChildren

_in_fstring = False

def JOINEDSTR(self, node):
    if (
            # the conversion / etc. flags are parsed as f-strings without
            # placeholders
            not self._in_fstring and
            not any(isinstance(x, ast.FormattedValue) for x in node.values)
    ):
        self.report(messages.FStringMissingPlaceholders, node)

    self._in_fstring, orig = True, self._in_fstring
    try:
        self.handleChildren(node)
    finally:
        self._in_fstring = orig
</t>
<t tx="ekr.20250430053636.140">def DICT(self, node):
    # Complain if there are duplicate keys with different values
    # If they have the same value it's not going to cause potentially
    # unexpected behaviour so we'll not complain.
    keys = [
        convert_to_value(key) for key in node.keys
    ]

    key_counts = counter(keys)
    duplicate_keys = [
        key for key, count in key_counts.items()
        if count &gt; 1
    ]

    for key in duplicate_keys:
        key_indices = [i for i, i_key in enumerate(keys) if i_key == key]

        values = counter(
            convert_to_value(node.values[index])
            for index in key_indices
        )
        if any(count == 1 for value, count in values.items()):
            for key_index in key_indices:
                key_node = node.keys[key_index]
                if isinstance(key, VariableKey):
                    self.report(messages.MultiValueRepeatedKeyVariable,
                                key_node,
                                key.name)
                else:
                    self.report(
                        messages.MultiValueRepeatedKeyLiteral,
                        key_node,
                        key,
                    )
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.141">def IF(self, node):
    if isinstance(node.test, ast.Tuple) and node.test.elts != []:
        self.report(messages.IfTuple, node)
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.142">IFEXP = IF

def ASSERT(self, node):
    if isinstance(node.test, ast.Tuple) and node.test.elts != []:
        self.report(messages.AssertTuple, node)
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.143">def GLOBAL(self, node):
    """
    Keep track of globals declarations.
    """
    global_scope_index = 1 if self._in_doctest() else 0
    global_scope = self.scopeStack[global_scope_index]

    # Ignore 'global' statement in global scope.
    if self.scope is not global_scope:

        # One 'global' statement can bind multiple (comma-delimited) names.
        for node_name in node.names:
            node_value = Assignment(node_name, node)

            # Remove UndefinedName messages already reported for this name.
            # TODO: if the global is not used in this scope, it does not
            # become a globally defined name.  See test_unused_global.
            self.messages = [
                m for m in self.messages if not
                isinstance(m, messages.UndefinedName) or
                m.message_args[0] != node_name]

            # Bind name to global scope if it doesn't exist already.
            global_scope.setdefault(node_name, node_value)

            # Bind name to non-global scopes, but as already "used".
            node_value.used = (global_scope, node)
            for scope in self.scopeStack[global_scope_index + 1:]:
                scope[node_name] = node_value
</t>
<t tx="ekr.20250430053636.144">NONLOCAL = GLOBAL

def GENERATOREXP(self, node):
    with self.in_scope(GeneratorScope):
        self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.145">LISTCOMP = DICTCOMP = SETCOMP = GENERATOREXP

def NAME(self, node):
    """
    Handle occurrence of Name (which can be a load/store/delete access.)
    """
    # Locate the name in locals / function / globals scopes.
    if isinstance(node.ctx, ast.Load):
        self.handleNodeLoad(node, self.getParent(node))
        if (node.id == 'locals' and isinstance(self.scope, FunctionScope) and
                isinstance(node._pyflakes_parent, ast.Call)):
            # we are doing locals() call in current scope
            self.scope.usesLocals = True
    elif isinstance(node.ctx, ast.Store):
        self.handleNodeStore(node)
    elif isinstance(node.ctx, ast.Del):
        self.handleNodeDelete(node)
    else:
        # Unknown context
        raise RuntimeError(f"Got impossible expression context: {node.ctx!r}")
</t>
<t tx="ekr.20250430053636.146">def CONTINUE(self, node):
    # Walk the tree up until we see a loop (OK), a function or class
    # definition (not OK), for 'continue', a finally block (not OK), or
    # the top module scope (not OK)
    n = node
    while hasattr(n, '_pyflakes_parent'):
        n, n_child = n._pyflakes_parent, n
        if isinstance(n, (ast.While, ast.For, ast.AsyncFor)):
            # Doesn't apply unless it's in the loop itself
            if n_child not in n.orelse:
                return
        if isinstance(n, (ast.FunctionDef, ast.ClassDef)):
            break
    if isinstance(node, ast.Continue):
        self.report(messages.ContinueOutsideLoop, node)
    else:  # ast.Break
        self.report(messages.BreakOutsideLoop, node)
</t>
<t tx="ekr.20250430053636.147">BREAK = CONTINUE

def RETURN(self, node):
    if isinstance(self.scope, (ClassScope, ModuleScope)):
        self.report(messages.ReturnOutsideFunction, node)
        return

    if (
        node.value and
        hasattr(self.scope, 'returnValue') and
        not self.scope.returnValue
    ):
        self.scope.returnValue = node.value
    self.handleNode(node.value, node)
</t>
<t tx="ekr.20250430053636.148">def YIELD(self, node):
    if isinstance(self.scope, (ClassScope, ModuleScope)):
        self.report(messages.YieldOutsideFunction, node)
        return

    self.handleNode(node.value, node)
</t>
<t tx="ekr.20250430053636.149">AWAIT = YIELDFROM = YIELD

def FUNCTIONDEF(self, node):
    for deco in node.decorator_list:
        self.handleNode(deco, node)

    with self._type_param_scope(node):
        self.LAMBDA(node)

    self.addBinding(node, FunctionDefinition(node.name, node))
    # doctest does not process doctest within a doctest,
    # or in nested functions.
    if (self.withDoctest and
            not self._in_doctest() and
            not isinstance(self.scope, FunctionScope)):
        self.deferFunction(lambda: self.handleDoctests(node))
</t>
<t tx="ekr.20250430053636.150">ASYNCFUNCTIONDEF = FUNCTIONDEF

def LAMBDA(self, node):
    args = []
    annotations = []

    for arg in node.args.posonlyargs:
        args.append(arg.arg)
        annotations.append(arg.annotation)
    for arg in node.args.args + node.args.kwonlyargs:
        args.append(arg.arg)
        annotations.append(arg.annotation)
    defaults = node.args.defaults + node.args.kw_defaults

    has_annotations = not isinstance(node, ast.Lambda)

    for arg_name in ('vararg', 'kwarg'):
        wildcard = getattr(node.args, arg_name)
        if not wildcard:
            continue
        args.append(wildcard.arg)
        if has_annotations:
            annotations.append(wildcard.annotation)

    if has_annotations:
        annotations.append(node.returns)

    if len(set(args)) &lt; len(args):
        for (idx, arg) in enumerate(args):
            if arg in args[:idx]:
                self.report(messages.DuplicateArgument, node, arg)

    for annotation in annotations:
        self.handleAnnotation(annotation, node)

    for default in defaults:
        self.handleNode(default, node)

    def runFunction():
        with self.in_scope(FunctionScope):
            self.handleChildren(
                node,
                omit=('decorator_list', 'returns', 'type_params'),
            )

    self.deferFunction(runFunction)
</t>
<t tx="ekr.20250430053636.151">def ARGUMENTS(self, node):
    self.handleChildren(node, omit=('defaults', 'kw_defaults'))
</t>
<t tx="ekr.20250430053636.152">def ARG(self, node):
    self.addBinding(node, Argument(node.arg, self.getScopeNode(node)))
</t>
<t tx="ekr.20250430053636.153">def CLASSDEF(self, node):
    """
    Check names used in a class definition, including its decorators, base
    classes, and the body of its definition.  Additionally, add its name to
    the current scope.
    """
    for deco in node.decorator_list:
        self.handleNode(deco, node)

    with self._type_param_scope(node):
        for baseNode in node.bases:
            self.handleNode(baseNode, node)
        for keywordNode in node.keywords:
            self.handleNode(keywordNode, node)
        with self.in_scope(ClassScope):
            # doctest does not process doctest within a doctest
            # classes within classes are processed.
            if (self.withDoctest and
                    not self._in_doctest() and
                    not isinstance(self.scope, FunctionScope)):
                self.deferFunction(lambda: self.handleDoctests(node))
            for stmt in node.body:
                self.handleNode(stmt, node)

    self.addBinding(node, ClassDefinition(node.name, node))
</t>
<t tx="ekr.20250430053636.154">def AUGASSIGN(self, node):
    self.handleNodeLoad(node.target, node)
    self.handleNode(node.value, node)
    self.handleNode(node.target, node)
</t>
<t tx="ekr.20250430053636.155">def TUPLE(self, node):
    if isinstance(node.ctx, ast.Store):
        # Python 3 advanced tuple unpacking: a, *b, c = d.
        # Only one starred expression is allowed, and no more than 1&lt;&lt;8
        # assignments are allowed before a stared expression. There is
        # also a limit of 1&lt;&lt;24 expressions after the starred expression,
        # which is impossible to test due to memory restrictions, but we
        # add it here anyway
        has_starred = False
        star_loc = -1
        for i, n in enumerate(node.elts):
            if isinstance(n, ast.Starred):
                if has_starred:
                    self.report(messages.TwoStarredExpressions, node)
                    # The SyntaxError doesn't distinguish two from more
                    # than two.
                    break
                has_starred = True
                star_loc = i
        if star_loc &gt;= 1 &lt;&lt; 8 or len(node.elts) - star_loc - 1 &gt;= 1 &lt;&lt; 24:
            self.report(messages.TooManyExpressionsInStarredAssignment, node)
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.156">LIST = TUPLE

def IMPORT(self, node):
    for alias in node.names:
        if '.' in alias.name and not alias.asname:
            importation = SubmoduleImportation(alias.name, node)
        else:
            name = alias.asname or alias.name
            importation = Importation(name, node, alias.name)
        self.addBinding(node, importation)
</t>
<t tx="ekr.20250430053636.157">def IMPORTFROM(self, node):
    if node.module == '__future__':
        if not self.futuresAllowed:
            self.report(messages.LateFutureImport, node)
    else:
        self.futuresAllowed = False

    module = ('.' * node.level) + (node.module or '')

    for alias in node.names:
        name = alias.asname or alias.name
        if node.module == '__future__':
            importation = FutureImportation(name, node, self.scope)
            if alias.name not in __future__.all_feature_names:
                self.report(messages.FutureFeatureNotDefined,
                            node, alias.name)
            if alias.name == 'annotations':
                self.annotationsFutureEnabled = True
        elif alias.name == '*':
            if not isinstance(self.scope, ModuleScope):
                self.report(messages.ImportStarNotPermitted,
                            node, module)
                continue

            self.scope.importStarred = True
            self.report(messages.ImportStarUsed, node, module)
            importation = StarImportation(module, node)
        else:
            importation = ImportationFrom(name, node,
                                          module, alias.name)
        self.addBinding(node, importation)
</t>
<t tx="ekr.20250430053636.158">def TRY(self, node):
    handler_names = []
    # List the exception handlers
    for i, handler in enumerate(node.handlers):
        if isinstance(handler.type, ast.Tuple):
            for exc_type in handler.type.elts:
                handler_names.append(getNodeName(exc_type))
        elif handler.type:
            handler_names.append(getNodeName(handler.type))

        if handler.type is None and i &lt; len(node.handlers) - 1:
            self.report(messages.DefaultExceptNotLast, handler)
    # Memorize the except handlers and process the body
    self.exceptHandlers.append(handler_names)
    for child in node.body:
        self.handleNode(child, node)
    self.exceptHandlers.pop()
    # Process the other nodes: "except:", "else:", "finally:"
    self.handleChildren(node, omit='body')
</t>
<t tx="ekr.20250430053636.159">TRYSTAR = TRY

def EXCEPTHANDLER(self, node):
    if node.name is None:
        self.handleChildren(node)
        return

    # If the name already exists in the scope, modify state of existing
    # binding.
    if node.name in self.scope:
        self.handleNodeStore(node)

    # 3.x: the name of the exception, which is not a Name node, but a
    # simple string, creates a local that is only bound within the scope of
    # the except: block. As such, temporarily remove the existing binding
    # to more accurately determine if the name is used in the except:
    # block.

    try:
        prev_definition = self.scope.pop(node.name)
    except KeyError:
        prev_definition = None

    self.handleNodeStore(node)
    self.handleChildren(node)

    # See discussion on https://github.com/PyCQA/pyflakes/pull/59

    # We're removing the local name since it's being unbound after leaving
    # the except: block and it's always unbound if the except: block is
    # never entered. This will cause an "undefined name" error raised if
    # the checked code tries to use the name afterwards.
    #
    # Unless it's been removed already. Then do nothing.

    try:
        binding = self.scope.pop(node.name)
    except KeyError:
        pass
    else:
        if not binding.used:
            self.report(messages.UnusedVariable, node, node.name)

    # Restore.
    if prev_definition:
        self.scope[node.name] = prev_definition
</t>
<t tx="ekr.20250430053636.160">def ANNASSIGN(self, node):
    self.handleAnnotation(node.annotation, node)
    # If the assignment has value, handle the *value* now.
    if node.value:
        # If the annotation is `TypeAlias`, handle the *value* as an annotation.
        if _is_typing(node.annotation, 'TypeAlias', self.scopeStack):
            self.handleAnnotation(node.value, node)
        else:
            self.handleNode(node.value, node)
    self.handleNode(node.target, node)
</t>
<t tx="ekr.20250430053636.161">def COMPARE(self, node):
    left = node.left
    for op, right in zip(node.ops, node.comparators):
        if (
                isinstance(op, (ast.Is, ast.IsNot)) and (
                    _is_const_non_singleton(left) or
                    _is_const_non_singleton(right)
                )
        ):
            self.report(messages.IsLiteral, node)
        left = right

    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.162">MATCH = MATCH_CASE = MATCHCLASS = MATCHOR = MATCHSEQUENCE = handleChildren
MATCHSINGLETON = MATCHVALUE = handleChildren

def _match_target(self, node):
    self.handleNodeStore(node)
    self.handleChildren(node)
</t>
<t tx="ekr.20250430053636.163">MATCHAS = MATCHMAPPING = MATCHSTAR = _match_target

@contextlib.contextmanager
def _type_param_scope(self, node):
    with contextlib.ExitStack() as ctx:
        if sys.version_info &gt;= (3, 12):
            ctx.enter_context(self.in_scope(TypeScope))
            for param in node.type_params:
                self.handleNode(param, node)
        yield
</t>
<t tx="ekr.20250430053636.164">def TYPEVAR(self, node):
    self.handleNodeStore(node)
    self.handle_annotation_always_deferred(node.bound, node)
</t>
<t tx="ekr.20250430053636.165">PARAMSPEC = TYPEVARTUPLE = handleNodeStore

def TYPEALIAS(self, node):
    self.handleNode(node.name, node)
    with self._type_param_scope(node):
        self.handle_annotation_always_deferred(node.value, node)
</t>
<t tx="ekr.20250430053636.61">class Checker:
    """I check the cleanliness and sanity of Python code."""
    
    _ast_node_scope = {
        ast.Module: ModuleScope,
        ast.ClassDef: ClassScope,
        ast.FunctionDef: FunctionScope,
        ast.AsyncFunctionDef: FunctionScope,
        ast.Lambda: FunctionScope,
        ast.ListComp: GeneratorScope,
        ast.SetComp: GeneratorScope,
        ast.GeneratorExp: GeneratorScope,
        ast.DictComp: GeneratorScope,
    }

    nodeDepth = 0
    offset = None
    _in_annotation = AnnotationState.NONE

    builtIns = set(builtin_vars).union(_MAGIC_GLOBALS)
    _customBuiltIns = os.environ.get('PYFLAKES_BUILTINS')
    if _customBuiltIns:
        builtIns.update(_customBuiltIns.split(','))
    del _customBuiltIns

    @others
</t>
<t tx="ekr.20250430053636.96">def __init__(self, tree, filename='(none)', builtins=None,
             withDoctest='PYFLAKES_DOCTEST' in os.environ, file_tokens=()):
    self._nodeHandlers = {}
    self._deferred = collections.deque()
    self.deadScopes = []
    self.messages = []
    self.filename = filename
    if builtins:
        self.builtIns = self.builtIns.union(builtins)
    self.withDoctest = withDoctest
    self.exceptHandlers = [()]
    self.root = tree

    self.scopeStack = []
    try:
        scope_tp = Checker._ast_node_scope[type(tree)]
    except KeyError:
        raise RuntimeError('No scope implemented for the node %r' % tree)

    with self.in_scope(scope_tp):
        for builtin in self.builtIns:
            self.addBinding(None, Builtin(builtin))
        self.handleChildren(tree)
        self._run_deferred()

    self.checkDeadScopes()

    if file_tokens:
        warnings.warn(
            '`file_tokens` will be removed in a future version',
            stacklevel=2,
        )
</t>
<t tx="ekr.20250430053636.97">def deferFunction(self, callable):
    """
    Schedule a function handler to be called just before completion.

    This is used for handling function bodies, which must be deferred
    because code later in the file might modify the global scope. When
    `callable` is called, the scope at the time this is called will be
    restored, however it will contain any new bindings added to it.
    """
    self._deferred.append((callable, self.scopeStack[:], self.offset))
</t>
<t tx="ekr.20250430053636.98">def _run_deferred(self):
    orig = (self.scopeStack, self.offset)

    while self._deferred:
        handler, scope, offset = self._deferred.popleft()
        self.scopeStack, self.offset = scope, offset
        handler()

    self.scopeStack, self.offset = orig
</t>
<t tx="ekr.20250430053636.99">def _in_doctest(self):
    return (len(self.scopeStack) &gt;= 2 and
            isinstance(self.scopeStack[1], DoctestScope))
</t>
<t tx="ekr.20250501074906.1"></t>
<t tx="ekr.20250512055230.1">@language ini

[bdist_wheel]

# Supports Python 3, so universal should be zero.
universal=0

[metadata]

# Becomes the home-page in `pip show leo`.
url = https://leo-editor.github.io/leo-editor/

[flake8]

exclude =
    .git,
    __pycache__,

extend-ignore =

    # Don't check B020. It conflicts with Leo idioms like `for p in p.children():
    # Found for loop that reassigns the iterable it is iterating with each iterable value.
    B020

    # blank line contains whitespace
    # W293

    # Comments and continuation lines...

    # expected an indented block (comment)
    E115

    # unexpected indentation (comment)
    E116

    # over-indented (comment)
    E117

    # continuation line over-indented for visual indent
    E127

    # continuation line missing indentation or outdented.
    E122

    # closing bracket does not match visual indentation.
    E124

    # continuation line with same indent as next logical line
    E125

    # continuation line under-indented for visual indent.
    E128

    # visually indented line with same indent as next logical line
    E129

    # continuation line unaligned for hanging indent.
    E131

    # whitespace before ':'
    # Conflict between black and flake8.
    E203

    # whitespace before '['
    # E211

    # multiple spaces before operator
    # Conflicts with extra spacing in @nobeautify nodes.
    E221

    # multiple spaces after operator
    # Conflicts with extra spacing in @nobeautify nodes.
    E222

    # missing whitespace around operator
    # Conflicts with extra spacing in @nobeautify nodes.
    # E225

    # missing whitespace after ','
    # E231

    # unexpected spaces around keyword / parameter equals
    # Conflicts with extra spacing in @nobeautify nodes.
    E251

    # at least two spaces before inline comment
    # E261

    # missing whitespace around parameter equals.
    # E252

    # inline comment should start with '# '
    E262

    # block comment should start with '# '.
    E265

    # too many leading '#' for block comment
    # Prohibits ### comments.
    E266

    # multiple spaces before keyword
    # Interferes with @nobeautify
    E272

    # missing whitespace after keyword.
    # Interferes with @nobeautify. Also warns about assert(whatever) and except(list).
    E275

    # trailing whitespace
    # E293

    # expected 1 blank line, found 0.
    E301

    # expected 2 blank lines, found 1.
    E302

    # whitespace before ':'
    # E203

    # too many blank lines (2)
    E303

    # expected 2 blank lines after class or function definition, found 0.
    E305

    # expected 1 blank line before a nested definition, found 0.
    E306
    
    # module level import not at top of file
    E402

    # Line too long.
    E501

    # global `whatever` is unused: name is never assigned in scope.
    # F824
</t>
<t tx="ekr.20250512060544.1">"""Run semantic_check.py with `python -c semanic_check.py."""
import os

g.cls()
os.chdir(r'C:\Repos\ekr-semantic-cache\semantic_cache\src')
g.execute_shell_commands([
    # 'dir',
    "python controller.py"
])
print('Done')  # , os.getcwd())</t>
<t tx="ekr.20250512061621.1">"""Run all unittests in the tests/test.py"""
import os

g.cls()
os.chdir(r'C:\Repos\ekr-semantic-cache\semantic_cache')
g.execute_shell_commands([
    "python -m unittest tests.test"  # --verbose
])
print('Done')
</t>
<t tx="ekr.20250512062255.1">def test_import(self):
    assert TestCase is not None
</t>
<t tx="ekr.20250512073231.1">class CacheTests(TestCase):
    @others
</t>
<t tx="ekr.20250514055617.1">def main(self) -&gt; None:
    assert g.app is None, repr(g.app)
    assert g.unitTesting is False
    updated_files = self.get_changed_files()
    if updated_files:
        self.do_semantics(updated_files)
        self.write_cache()
        self.commit()
    self.close()
    t2 = time.perf_counter()
    self.stats.append(('Total', t2 - self.start_time))
    self.print_stats(updated_files)
</t>
<t tx="ekr.20250514060210.1">def test_times(self):
    # Report various times.
    from src.controller import core_path, core_names
    from src.controller import parse_ast
    from src.controller import CacheController
    x = CacheController()

    # Precheck.
    paths = [f"{core_path}{os.sep}{z}.py" for z in core_names]
    for path in paths:
        assert os.path.exists(path), repr(path)

    # Time to get all modification times.
    t1 = time.perf_counter()
    mod_time_dict: dict[str, float] = {}
    for path in paths:
        mod_time_dict[path] = os.path.getmtime(path)

    # Time to parse all files.
    t2 = time.perf_counter()
    contents_dict: dict[str, str] = {}
    for path in paths:
        contents_dict[path] = g.readFile(path)

    # Time to parse all files.
    t3 = time.perf_counter()
    tree_dict: dict[path, ast.AST] = {}
    for path in paths:
        tree_dict[path] = parse_ast(contents_dict[path])

    # Totals.
    t4 = time.perf_counter()
    x.stats.append(('Read all mod times', t2 - t1))
    x.stats.append(('Read all files', t3 - t2))
    x.stats.append(('Parse all files', t4 - t3))
    # x.stats.append(('Test', 2.61))
    x.print_stats(paths)
</t>
<t tx="ekr.20250514145537.1">test
run
check
backup
</t>
<t tx="ekr.20250514145634.1"></t>
<t tx="ekr.20250515061233.1"></t>
<t tx="ekr.20250515075715.1">    lines = g.splitlines(dump_ast(tree))
    for i, line in enumerate(lines[:30]):
        print(f"{i:2} {line.rstrip()}")</t>
<t tx="ekr.20250515081830.1">True: run flake8 on each saved file, but only if it has been changed.</t>
<t tx="ekr.20250515081904.1"></t>
<t tx="ekr.20250515082911.1"></t>
</tnodes>
</leo_file>
